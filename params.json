{
  "name": "Easy-to-Understand Computed Tomography ",
  "tagline": "Simple and Educational Parallel-Beam Computed Tomography Simulator (Implemented Both in MATLAB and CUDA)",
  "body": "# Why Did I Do This?\r\nWhen I first learned how computed tomography worked, it was mostly through mathematics and I never implemented the algorithms to perform the image reconstruction myself. Instead, I used MATLAB built-in functions like radon and iradon to do things for me. The obvious downside to using these built-ins was that I never got to understand and implement the actual algorithms. The few resources I could find had very complicated implementations and did a poor job of helping me to understand how to implement these algorithms from scratch. \r\n\r\nFortunately, after some time, I implemented a simple and easy-to-understand parallel-beam CT system in MATLAB without the use of radon and iradon. All the MATLAB files are short and well-commented, and I make extensive use of meshgrid, interp1, and interp2 functions to simplify many steps in the algorithms. \r\n\r\nThe goal of this code is NOT to provide a comprehensive toolkit that enables you to reconstruct an image for an arbitrary CT system, but rather to provide key insights on how a simple parallel-beam CT system works. Once this simple example is understood, it should be much easier to simulate larger CT systems with different imaging geometries, because at that point, CT really just becomes a big geometry problem. \r\n\r\n# Elegant and Simple Derivation\r\n## What does a CT system do?\r\nA CT system effectively takes multiple projections of an object and tries to estimate what the object looks like at every point in space based on those projections. Here we say that the intensity of the object we are taking the projections of is f(x,y). In this parallel-beam geometry, in order to project f(x,y) onto a line, we must integrate f(x,y) along lines orthogonal to the line (...really plane) we are projecting onto. If we rotate this projection line, we can show how this projected profile changes as a function of angle: this is known as the sinogram or radon transform of f(x,y). \r\n\r\n![](https://cloud.githubusercontent.com/assets/10136046/18261138/5d015ace-73a9-11e6-9224-a74f51d615e8.png)\r\n\r\nAs it turns out, the projection of an object onto a plane can be analyzed using the Fourier-Slice (or Projection-Slice) Theorem, which basically says the Fourier transform of the projection of an object directly gives you values in the Fourier domain representation of the object. See the brief explanation of Fourier-Slice Theorem below:\r\n\r\n![](https://cloud.githubusercontent.com/assets/10136046/18261140/5d285110-73a9-11e6-9edd-7ee35c30b88f.png)\r\n\r\nNow that we understand how a CT system takes projections of an object at various angles and how Fourier Slice Theorem can be used to recover the Fourier spectrum of the object we are trying to reconstruct, we can now derive the process needed to reconstruct the object based on its projections: \r\n\r\n![](https://cloud.githubusercontent.com/assets/10136046/18261139/5d274a68-73a9-11e6-9a66-14fdcb298354.png)\r\n\r\nNote that the result provides an exact algorithm on how to exactly recover the object function f(x,y). We first have to ramp filter the sinogram. This basically means multiplying the Fourier transform of each projection profile by the absolute value of frequency and then taking the inverse Fourier transform. We then backproject this ramp-filtered sinogram back into the image we are trying to reconstruct. The best way to visualize this is to pretend that the reconstructed image starts off as a blank canvas. Then, we take the ramp-filtered profile and smear it into the canvas at the angle the profile was initially projected at. **Example Demonstration** illustrates these steps.\r\n\r\n## Example Demonstration\r\n### Original Object Image\r\nHere is the object I am trying to take projections of and reconstruct:\r\n![](https://cloud.githubusercontent.com/assets/10136046/18263005/64185db4-73bb-11e6-88ac-d5acdaa310c1.png)\r\n### Sinogram and Ramp Filtering\r\nThe image on the left shows the sinogram produced when simply projecting the image onto a line at various angles. The image on the right shows a ramp-filtered version of the same sinogram. Here ramp-filtering was applied to each row of the sinogram (each projection at a particular angle).\r\n![](https://cloud.githubusercontent.com/assets/10136046/18263009/67fa0c16-73bb-11e6-915e-83f1830e990c.png)\r\n### Backprojection Animation\r\nHere you can see how each ramp-filtered projection gets smeared back into the reconstruction. As the “back-projections” accumulate, we start to see the original object.\r\n\r\n![](https://cloud.githubusercontent.com/assets/10136046/18263016/73646e02-73bb-11e6-96ef-87d45e4cbcf6.gif)\r\n\r\n# Implementation\r\n## Simple Easy MATLAB\r\nThe **CT_ReconExample.m** script under the **Simple Intuitive MATLAB** directory of my repository runs all of the following functions and shows an animated reconstruction.\r\n### Radon Transform / Sinogram Creation\r\nThe sinogram generating function sets the spacing and total span of detectors on the detector array based on the coordinates of pixels in the image. From this information we use meshgrid to generate **r_sensor** and **r_integration** which correspond to the coordinate along the detector array and the coordinate orthogonal to the detector array, respectively. We re-express **r_sensor** and **r_integration** in polar coordinates as **r_temp** and **theta_r** in order to easily rotate the detector and integration axes. The for loop iterates over rotation angle, uses interpolation to calculate the value of the image at points on the grid defined by the detector and integration axes, and sums along the integration axis;\r\n```\r\nfunction [r, sg] = sinogram(x, y, object, theta)\r\n%SINOGRAM Generate a Sinogram of the Image\r\n%   [r, sg] = sinogram(x, y, object, theta)\r\n%   x -- x coordinates of object: numel(x) must be equal to size(object,2)\r\n%   y -- y coordinates of object: numel(y) must be equal to size(object,1)\r\n%   object -- intensity of object as a function of x and y\r\n%   theta -- vector of angles (degrees) to take projections at\r\n\r\n% 1/dr = 1/dx + 1/dy: just a way to make sure dr is smaller than dx and dy\r\ndr = 1/(1/mean(diff(x))+ 1/mean(diff(y))); \r\n\r\n% get the number of elements on the sensor array\r\nrmax = sqrt(max(abs(x))^2 + max(abs(y))^2);\r\nrmax = dr*ceil(rmax/dr);\r\n\r\n% give coordinate for each element relative to the center of sensor array\r\nr = -rmax:dr:rmax; \r\n[r_sensor, r_integration] = meshgrid(r,r);\r\nr_temp = sqrt(r_sensor.^2 + r_integration.^2);\r\ntheta_r = atan2(r_integration, r_sensor);\r\n\r\n% get X, Y, R, and THETA for all points in object\r\n[X, Y] = meshgrid(x,y);\r\n\r\n% Set aside space for the sinogram\r\nsg = zeros(numel(theta), numel(r));\r\n\r\n% Now Construct the sinogram\r\nfor theta_idx = 1:numel(theta)\r\n    obj_rotated = interp2(X, Y, object, ...\r\n        r_temp.*cos(theta_r + deg2rad(theta(theta_idx))), ...\r\n        r_temp.*sin(theta_r + deg2rad(theta(theta_idx))), 'linear', 0);\r\n    sg(theta_idx,:) = sum(obj_rotated);\r\nend\r\n\r\nend\r\n```\r\n\r\n### Ramp-Filtering the Sinogram\r\nHere we simply take an FFT of the sinogram along the detector coordinate. Then we multiply each projection spectrum with the ramp profile. Finally we take an inverse FFT along the detector coordinate to get the ramp-filtered sinogram.\r\n\r\n```\r\nfunction sg_rampfiltered = rampFilt(sg)\r\n%RAMPFILT Apply Ramp Filter to Sinogram\r\n%   sg_rampfiltered = rampFilt(sg)\r\n%   Each row is a different angle of projection\r\n%   Each column is a different sensor on the array\r\n\r\n[numAngles, numSensors] = size(sg);\r\nSG = fftshift(fft(sg')',2); % Take FFT of Sensor Data at Each Angle\r\nramp = ones(numAngles,1)*abs(-ceil((numSensors-1)/2):floor((numSensors-1)/2));\r\nSG_rampfiltered = SG .* ramp; % Apply our ramp filter to the FFT\r\nsg_rampfiltered = ifft(ifftshift(SG_rampfiltered,2)')';\r\n\r\nend\r\n```\r\n\r\n### Backprojecting the Ramp-Filtered Sinogram\r\nRecall the backprojection summation (integral) we derived:\r\n![](https://cloud.githubusercontent.com/assets/10136046/18264599/0f887ada-73c6-11e6-8357-9b583aa3179d.png)\r\nThe function which performs the backprojection does pretty much the same thing: \r\n```\r\nfunction recon_img = backproj(r_sensor, theta, sg, x, y, animation)\r\n%BACKPROJ Backprojection Reconstruction Based on Sinogram\r\n%   [x, y, recon_img] = backproj(r_sensor, theta, sg)\r\n%   r_sensor -- positions of sensors on array\r\n%   theta -- angles (in degrees) at which projections were taken\r\n%   sg -- sinogram (sensor as columns; rows as degrees)\r\n%   x -- x location of pixels in reconstruction (vector)\r\n%   y -- y location of pixels in reconstruction (vector)\r\n%   animation -- set this to true to show reconstruction\r\n%   recon_img -- reconstructed image\r\n\r\n% Set up coordinates for reconstructed image\r\n[X, Y] = meshgrid(x,y);\r\nrecon_img = zeros(size(X));\r\n\r\nfor theta_idx = 1:numel(theta)\r\n    recon_img = recon_img + interp1(r_sensor, sg(theta_idx,:), ...\r\n        X*cosd(theta(theta_idx))+Y*sind(theta(theta_idx)), 'linear', 0);\r\nend\r\n\r\nend\r\n```\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}